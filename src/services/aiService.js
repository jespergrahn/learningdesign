// Google Gemini AI Service
import { GoogleGenerativeAI } from '@google/generative-ai';

// Du beh√∂ver s√§tta din API-nyckel h√§r
// Skaffa en gratis p√•: https://makersuite.google.com/app/apikey
const API_KEY = process.env.REACT_APP_GEMINI_API_KEY || 'DIN_API_NYCKEL_H√ÑR';

let genAI;
let model;

try {
  genAI = new GoogleGenerativeAI(API_KEY);
  // Anv√§nd latest-alias som alltid pekar p√• senaste fungerande versionen
  model = genAI.getGenerativeModel({ 
    model: 'gemini-flash-latest'
  });
  console.log('Gemini model initierad: gemini-flash-latest');
} catch (error) {
  console.error('Fel vid initiering av Gemini:', error);
}

// System prompt som definierar AI:ns beteende
const SYSTEM_PROMPT = `Du √§r en erfaren pedagogisk designexpert och coach som hj√§lper anv√§ndare att skapa RIKTIGT BRA utbildningar. Du har h√∂ga krav och coachar anv√§ndaren till djupare insikter.

Din personlighet:
- V√§nlig men kr√§vande - du vill ha kvalitet
- Nyfiken och utforskande - gr√§v djupare
- Anv√§nd emojis ibland f√∂r att g√∂ra samtalet trevligt (men inte i varje mening)
- St√§ll f√∂ljdfr√•gor n√§r svaret √§r f√∂r ytligt
- Utmana anv√§ndaren att t√§nka mer konkret och specifikt

VIKTIGT - Regler f√∂r coaching:
- St√§ll ENDAST EN fr√•ga √•t g√•ngen
- Acceptera INTE f√∂r ytliga eller vaga svar
- Om svaret √§r f√∂r generellt: St√§ll f√∂ljdfr√•gor f√∂r att g√• djupare
- Om svaret √§r bra och konkret: Bekr√§fta och s√§g "Perfekt! Jag l√§gger till det i din design! ‚úÖ"
- Var kortfattad (max 2-3 meningar + EN fr√•ga)
- Anv√§nd INTE Markdown-formatering (**, *, _) - skriv vanlig text
- Anv√§nd emojis ist√§llet f√∂r fetstil

Tecken p√• ETT BRA SVAR (l√§gg till i dashboard):
- Konkret och specifikt (inte vagt)
- Beskriver verkliga situationer eller exempel
- Visar djup f√∂rst√•else
- Inneh√•ller detaljer

Tecken p√• ETT D√ÖLIGT SVAR (coacha vidare):
-F√∂r vagt eller generellt
- "Vi beh√∂ver bli b√§ttre" (p√• vad konkret?)
- "L√§ra sig ledarskap" (vilka specifika f√§rdigheter?)
- Saknar konkreta exempel

Exempel p√• coaching:

ANV√ÑNDARE: "V√•ra chefer beh√∂ver bli b√§ttre p√• ledarskap"
DU: "Okej, jag f√∂rst√•r. Kan du ge mig ett konkret exempel p√• en situation d√§r du ser att ledarskapet brister? Vad h√§nder d√•? ü§î"

ANV√ÑNDARE: "De instruerar ist√§llet f√∂r att coacha n√§r medarbetare kommer med problem"
DU: "Perfekt! Det √§r ett konkret exempel. Jag l√§gger till det i din design! ‚úÖ N√§sta: Vad skulle g√∂ra denna utbildning framg√•ngsrik f√∂r er?"

Du guidar anv√§ndaren genom att ta fram en "High Level Design" f√∂r en utbildning med dessa delar (i denna ordning):

1. V√•r nuvarande utmaning √§r... (konkreta problem och situationer)
2. Denna utbildning kommer ses som framg√•ngsrik om... (m√§tbara framg√•ngskriterier)
3. M√•lgruppen (vem √§r utbildningen f√∂r)
4. Vad ska deltagarna l√§ra sig? (specifika f√§rdigheter/kunskaper)
5. Vad motiverar dem att l√§ra sig om √§mnet? (konkreta drivkrafter)
6. Vilka beteenden vill vi se mer av? (observerbara beteenden)
7. Vilka konkreta scenarion √§r det deltagarna har sv√•rt f√∂r idag? (verkliga situationer)

B√∂rja alltid med att fr√•ga om deras nuvarande utmaningar. Ta en del i taget. Coacha till kvalitet innan du g√•r vidare.`;

class AIService {
  constructor() {
    this.conversationHistory = [];
    this.currentSection = 'challenges'; // Vilken del av designen vi jobbar med
    this.sections = [
      'challenges',
      'success',
      'targetAudience',
      'learningGoals',
      'motivation',
      'behaviors',
      'scenarios'
    ];
  }

  async sendMessage(userMessage) {
    if (!model) {
      console.error('API Key:', API_KEY);
      return {
        response: '‚ö†Ô∏è AI-tj√§nsten √§r inte konfigurerad. Starta om servern (npm start) f√∂r att ladda API-nyckeln fr√•n .env filen.',
        extractedData: null
      };
    }

    try {
      // Bygg konversationskontext
      const context = this.buildContext(userMessage);
      
      console.log('Skickar till Gemini...');
      
      // Skicka till Gemini med retry-logik
      let result;
      try {
        result = await model.generateContent(context);
      } catch (error) {
        // Om vi f√•r 503 (overloaded) eller 429 (rate limit), v√§nta och f√∂rs√∂k igen
        if (error.message?.includes('503') || error.message?.includes('429') || error.message?.includes('overloaded')) {
          console.log('Modellen √∂verbelastad, v√§ntar 2 sekunder och f√∂rs√∂ker igen...');
          await new Promise(resolve => setTimeout(resolve, 2000));
          result = await model.generateContent(context);
        } else {
          throw error;
        }
      }
      
      const response = await result.response;
      const aiMessage = response.text();

      console.log('Svar fr√•n Gemini:', aiMessage);

      // Spara i historik
      this.conversationHistory.push(
        { role: 'user', content: userMessage },
        { role: 'assistant', content: aiMessage }
      );

      // Extrahera data fr√•n anv√§ndarens svar f√∂r att fylla i dashboarden
      const extractedData = this.extractDataFromUserMessage(userMessage);

      return {
        response: aiMessage,
        extractedData: extractedData
      };
    } catch (error) {
      console.error('Detaljerat fel vid kommunikation med AI:', error);
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
      
      // Ge anv√§ndarv√§nligt felmeddelande
      let errorMsg = 'üòÖ N√•got gick fel med AI:n.';
      if (error.message?.includes('403')) {
        errorMsg = '‚ö†Ô∏è API-nyckeln har n√•tt sin dagsgr√§ns. Du kan forts√§tta manuellt eller v√§nta till imorgon.';
      } else if (error.message?.includes('503') || error.message?.includes('overloaded')) {
        errorMsg = '‚è≥ AI:n √§r lite √∂verbelastad just nu. V√§nta n√•gra sekunder och f√∂rs√∂k igen.';
      } else if (error.message?.includes('429')) {
        errorMsg = '‚è∏Ô∏è F√∂r m√•nga f√∂rfr√•gningar. V√§nta en minut och f√∂rs√∂k igen.';
      }
      
      return {
        response: errorMsg,
        extractedData: null
      };
    }
  }

  buildContext(userMessage) {
    // Bygg en prompt med systemkontext och historik
    let context = SYSTEM_PROMPT + '\n\n';
    context += 'Konversationshistorik:\n';
    
    this.conversationHistory.forEach(msg => {
      const role = msg.role === 'user' ? 'Anv√§ndare' : 'Du';
      context += `${role}: ${msg.content}\n`;
    });
    
    context += `Anv√§ndare: ${userMessage}\n`;
    context += 'Du:';
    
    return context;
  }

  extractDataFromUserMessage(message) {
    // Extrahera bara om svaret √§r tillr√§ckligt bra (minst 20 tecken f√∂r att vara konkret)
    if (message.trim().length < 20) return null;
    
    // Returnera data f√∂r aktuell sektion
    return {
      section: this.currentSection,
      value: message.trim()
    };
  }

  getCurrentSectionName() {
    const sectionNames = {
      'challenges': 'nuvarande utmaningar',
      'success': 'framg√•ngskriterier',
      'targetAudience': 'm√•lgruppen',
      'learningGoals': 'l√§randem√•l',
      'motivation': 'motivation',
      'behaviors': '√∂nskade beteenden',
      'scenarios': 'konkreta scenarion'
    };
    return sectionNames[this.currentSection] || 'n√§sta steg';
  }

  moveToNextSection() {
    const currentIndex = this.sections.indexOf(this.currentSection);
    if (currentIndex < this.sections.length - 1) {
      this.currentSection = this.sections[currentIndex + 1];
    }
  }

  reset() {
    this.conversationHistory = [];
    this.currentSection = 'challenges';
  }
}

export default new AIService();
